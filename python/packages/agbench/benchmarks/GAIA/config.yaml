# config.yaml
#
# The contents of this file will be copied into the 'config.yaml' file of
# every expanded Task, just prior to running the scenario. This provides a
# good place to store model or other configurations important for the scenario.

###############################
# Open AI model configuration #
###############################
# model_config: &client
#   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
#   config:
#     model: gpt-5-nano


##############################
# Ollama model configuration #
##############################
model_config: &client
   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
   config:
     model: qwen3:32b
     base_url: http://localhost:11434/v1/
     api_key: ollama
     model_info:
       function_calling: true
       json_output: true
       vision: false
       family: qwen
       structured_output: true


# model_config: &client
#   provider: autogen_ext.models.openai.OpenAIChatCompletionClient
#   config:
#     model: qwen2.5vl:32b
#     base_url: https://b1de0f06d9bf.ngrok-free.app/v1/chat/
#     api_key: ollama
#     model_info:
#       function_calling: true
#       json_output: true
#       vision: true
#       family: qwen
#       structured_output: true


#######################
# Used by MagenticOne #
#######################
orchestrator_client: *client
coder_client: *client
web_surfer_client: *client
file_surfer_client: *client  